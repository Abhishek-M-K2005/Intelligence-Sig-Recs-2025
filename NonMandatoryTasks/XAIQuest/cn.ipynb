{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e53fa7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (2.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib seaborn scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73d0ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278a9eaa",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58861217",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoader:\n",
    "    \"\"\"Load and preprocess CIFAR-10 Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.num_classes = 10\n",
    "        self.class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def loadData(self):\n",
    "        \"\"\"Load dataset\"\"\"\n",
    "        print(\"Loading CIFAR-10 dataset.\")\n",
    "        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "        \n",
    "        print(f\"Training data shape: {x_train.shape}\")\n",
    "        print(f\"Test data shape: {x_test.shape}\")\n",
    "        return (x_train, y_train), (x_test, y_test)\n",
    "        \n",
    "    def preprocessData(self, x_train, y_train, x_test, y_test, normalize = True):\n",
    "        if normalize:\n",
    "            x_train = x_train.astype('float32') / 255.0\n",
    "            x_test = x_test.astype('float32') / 255.0\n",
    "            \n",
    "        y_train_c = keras.utils.to_categorical(y_train, self.num_classes)\n",
    "        y_test_c = keras.utils.to_categorical(y_test, self.num_classes)\n",
    "        \n",
    "        return x_train, y_train_c, x_test, y_test_c\n",
    "    \n",
    "    def createValidationSplit(self, x_train, y_train, val_split = 0.1):\n",
    "        valSize = int(len(x_train)* val_split)\n",
    "        \n",
    "        x_val = x_train[-valSize:]\n",
    "        y_val = y_train[-valSize:]\n",
    "        x_train = x_train[:-valSize]\n",
    "        y_train = y_train[:-valSize]\n",
    "        \n",
    "        print(f\"Training set: {x_train.shape[0]} samples\")\n",
    "        print(f\"Validation set: {x_val.shape[0]} samples\")\n",
    "        \n",
    "        return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab16fa",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5fdac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataAug():\n",
    "    data_aug = keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "    ], name = \"data_augmentaion\")\n",
    "    \n",
    "    return data_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b0507",
   "metadata": {},
   "source": [
    "# CNN model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edd95da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNArchitectures:\n",
    "    @staticmethod\n",
    "    def simpleCNN(input_shape=(32, 32, 3), num_classes=10):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", input_shape = input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\")\n",
    "        ], name = \"SimpleCNN\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def deep_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\", input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\", padding = \"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Conv2D(128, (3, 3), activation = \"relu\", padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2,2)),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Conv2D(256, (3, 3), activation=\"relu\", padding = \"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.4),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Densed(num_classes, activation=\"softmax\"),\n",
    "        ], name=\"DeepCNN\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def vgg_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "        model= models.Sequential([\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D((2, 2)), \n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.2),\n",
    "            \n",
    "            layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.3),\n",
    "            \n",
    "            layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n",
    "            layers.MaxPooling2D((2, 2)), \n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.4),\n",
    "            \n",
    "            layers.Flatten(),\n",
    "            layers.Dense(512, (3, 3), activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(512, (3, 3), activation=\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5), \n",
    "            layers.Dense(num_classes, activation=\"softmax\")          \n",
    "        ], name=\"VGG_Style\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def resnet_style(input_shape=(32, 32, 3), num_classes=10):\n",
    "        inputs=layers.Input(shape=input_shape)\n",
    "        \n",
    "        x = layers.Conv2D(64, 3, padding=\"same\")(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        \n",
    "        x = CNNArchitectures.residual_block(x, 64)\n",
    "        x = CNNArchitectures.residual_block(x, 64)\n",
    "        \n",
    "        x = CNNArchitectures.residual_block(x, 128, stride=2)\n",
    "        x = CNNArchitectures.residual_block(x, 128)\n",
    "        \n",
    "        x = CNNArchitectures.residual_block(x, 256, stride=2)\n",
    "        x = CNNArchitectures.residual_block(x, 256)\n",
    "        \n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        \n",
    "        outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "        \n",
    "        model = models.Model(inputs, outputs, name = \"ResNet_Style\")\n",
    "        \n",
    "        return model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97018698",
   "metadata": {},
   "source": [
    "# Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a034e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_train(model, x_train, y_train, x_val, y_val, epochs=50, batch_size = 64, learning_rate=0.001, use_augmentation=True):\n",
    "    #compile\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics = ['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name = \"top3_accuracy\")]\n",
    "    )\n",
    "    #callbacks and data augmentation got these functions from claude\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience = 10,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience = 5,\n",
    "            min_lr = 1e-7\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only = True\n",
    "        )        \n",
    "    ]\n",
    "    \n",
    "    if use_augmentation:\n",
    "        data_aug = createDataAug()\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "        train_dataset = train_dataset.shuffle(1000).batch(batch_size)\n",
    "        train_dataset = train_dataset.map(\n",
    "            lambda x, y: (data_aug(x, training=True), y),\n",
    "            num_parallel_calls = tf.data.AUTOTUNE\n",
    "        )\n",
    "        train_Dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        history = model.fit(\n",
    "            train_dataset, epochs = epochs,\n",
    "            validation_data = (x_val, y_val), \n",
    "            callbacks = callbacks,\n",
    "            verbose=0\n",
    "        )\n",
    "    else:\n",
    "        history = model.fit(\n",
    "            x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data = (x_val, y_val),\n",
    "            callbacks = callbacks,\n",
    "            verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f184e3",
   "metadata": {},
   "source": [
    "# Evaluation functins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28b2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, class_names):\n",
    "    print(\"MODEL EVAALUATION\")\n",
    "    \n",
    "    y_pred = model.predict(x_test, verbose = 0)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    test_loss, test_acc, test_top3 = model.evaluate(x_test, y_test, verbose = 0)\n",
    "    print(f\"\\nTest Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_acc} ({test_acc * 100}%)\")\n",
    "    print(f\"Top-3 Accuracy: {test_top3} ({test_top3 * 100}%)\")\n",
    "    \n",
    "    print(classification_report(y_true_classes, y_pred_classes, target_names=class_names, digits=4))\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = y_true_classes == i\n",
    "        class_acc = np.mean(y_pred_classes[class_mask] == i)\n",
    "        print(f\" {class_names}:{class_acc}\")\n",
    "        \n",
    "    return y_pred_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02029cde",
   "metadata": {},
   "source": [
    "Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f784df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10 dataset.\n",
      "Training data shape: (50000, 32, 32, 3)\n",
      "Test data shape: (10000, 32, 32, 3)\n",
      "Training set: 45000 samples\n",
      "Validation set: 5000 samples\n"
     ]
    }
   ],
   "source": [
    "data_loader = dataLoader()\n",
    "(x_train, y_train), (x_test, y_test) = data_loader.loadData()\n",
    "\n",
    "\n",
    "x_train, y_train_cat, x_test, y_test_cat = data_loader.preprocessData(\n",
    "    x_train, y_train, x_test, y_test\n",
    ")\n",
    "\n",
    "x_train, y_train_cat, x_val, y_val = data_loader.createValidationSplit(x_train, y_train_cat, val_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d58bc0",
   "metadata": {},
   "source": [
    "train multiple architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "401e7515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishekmarutikarennavar/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Model.summary of <Sequential name=SimpleCNN, built=True>>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "architectures={\n",
    "    \"simpleCNN\":CNNArchitectures.simpleCNN,\n",
    "    'deepCNN':CNNArchitectures.deep_cnn,\n",
    "    'vgg':CNNArchitectures.vgg_model,\n",
    "    'resnet':CNNArchitectures.resnet_style\n",
    "}\n",
    "\n",
    "results={}\n",
    "\n",
    "model = architectures['simpleCNN']()\n",
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437b57b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "history = compile_and_train(model, x_train, y_train_cat, x_val, y_val,\n",
    "                            epochs=30,\n",
    "                            batch_size=64,\n",
    "                            learning_rate=0.001,\n",
    "                            use_augmentation=True\n",
    "                            )\n",
    "results['simpleCNN'] = {\n",
    "    'model':model,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "y_pred = evaluate_model(model, x_test, y_test_cat, data_loader.class_names)\n",
    "\n",
    "y_true = np.argmax(y_test_cat, axis = 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0bd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architectures['deepcnn']()\n",
    "model.summary\n",
    "history = compile_and_train(model, x_train, y_train_cat, x_val, y_val,\n",
    "                            epochs=30,\n",
    "                            batch_size=64,\n",
    "                            learning_rate=0.001,\n",
    "                            use_augmentation=True\n",
    "                            )\n",
    "results['deepcnn'] = {\n",
    "    'model':model,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "y_pred = evaluate_model(model, x_test, y_test_cat, data_loader.class_names)\n",
    "\n",
    "y_true = np.argmax(y_test_cat, axis = 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b92363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architectures['vgg']()\n",
    "model.summary\n",
    "history = compile_and_train(model, x_train, y_train_cat, x_val, y_val,\n",
    "                            epochs=30,\n",
    "                            batch_size=64,\n",
    "                            learning_rate=0.001,\n",
    "                            use_augmentation=True\n",
    "                            )\n",
    "results['vgg'] = {\n",
    "    'model':model,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "y_pred = evaluate_model(model, x_test, y_test_cat, data_loader.class_names)\n",
    "\n",
    "y_true = np.argmax(y_test_cat, axis = 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = architectures['resnet']()\n",
    "model.summary\n",
    "history = compile_and_train(model, x_train, y_train_cat, x_val, y_val,\n",
    "                            epochs=30,\n",
    "                            batch_size=64,\n",
    "                            learning_rate=0.001,\n",
    "                            use_augmentation=True\n",
    "                            )\n",
    "results['resnet'] = {\n",
    "    'model':model,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "y_pred = evaluate_model(model, x_test, y_test_cat, data_loader.class_names)\n",
    "\n",
    "y_true = np.argmax(y_test_cat, axis = 1)\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b301992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
